<!doctype html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Monda:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Architecture,CPU,"><link rel="alternate" href="/atom.xml" title="HAMSTERSI" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="To make your applications take advantage of CPU microarchitectures, you need to know how the application is utilizing available hardware resources. One way to obtain this knowledge is by using on-chip"><meta property="og:type" content="article"><meta property="og:title" content="CPU Metrics Reference - General Exploration"><meta property="og:url" content="http://hamstersi.github.io/2017/03/CPU-Metrics-Reference-General-Exploration/index.html"><meta property="og:site_name" content="HAMSTERSI"><meta property="og:description" content="To make your applications take advantage of CPU microarchitectures, you need to know how the application is utilizing available hardware resources. One way to obtain this knowledge is by using on-chip"><meta property="og:image" content="http://wx1.sinaimg.cn/mw690/672d88aagy1fd8s0n9jsqj219r0c4n00.jpg"><meta property="og:image" content="http://wx4.sinaimg.cn/large/672d88aagy1fd8sap5wrqg20xc0h2jsp.gif"><meta property="og:updated_time" content="2017-03-02T13:39:28.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="CPU Metrics Reference - General Exploration"><meta name="twitter:description" content="To make your applications take advantage of CPU microarchitectures, you need to know how the application is utilizing available hardware resources. One way to obtain this knowledge is by using on-chip"><meta name="twitter:image" content="http://wx1.sinaimg.cn/mw690/672d88aagy1fd8s0n9jsqj219r0c4n00.jpg"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"always"},fancybox:!0,motion:!0,duoshuo:{userId:"6385485131666162433/",author:"Blogger"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://hamstersi.github.io/2017/03/CPU-Metrics-Reference-General-Exploration/"><title>CPU Metrics Reference - General Exploration | HAMSTERSI</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><script type="text/javascript">!function(){var e=document.createElement("script");e.src="//tajs.qq.com/stats?sId=60753873";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div style="display:none"><script src="//s95.cnzz.com/z_stat.php?id=1261299152&web_id=1261299152" language="JavaScript"></script></div><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="site-title">HAMSTERSI</span></a></div><p class="site-subtitle">生性涼薄 擇木而修</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-book"><a href="/books" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i><br>读书</a></li><li class="menu-item menu-item-film"><a href="/movies" rel="section"><i class="menu-item-icon fa fa-fw fa-film"></i><br>电影</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://hamstersi.github.io/2017/03/CPU-Metrics-Reference-General-Exploration/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Hamster Si"><meta itemprop="description" content=""><meta itemprop="image" content="/images/logo@2x.png"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="HAMSTERSI"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="HAMSTERSI" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">CPU Metrics Reference - General Exploration</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-text">发表</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-02T20:29:19+08:00">2017-03-02 </time></span><span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-text">分类</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span> </a></span></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-text">标签</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/tags/Architecture/" itemprop="url" rel="tag"><span itemprop="name">#Architecture</span> </a></span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/tags/CPU/" itemprop="url" rel="tag"><span itemprop="name">#CPU</span></a></span></span></div></header><div class="post-body" itemprop="articleBody"><script src="/assets/js/APlayer.min.js"></script><p>To make your applications take advantage of CPU microarchitectures, you need to know how the application is utilizing available hardware resources. One way to obtain this knowledge is by using on-chip Performance Monitoring Units (PMUs). PMUs are dedicated pieces of logic within a CPU core that count specific hardware events as they occur on the system. Examples of these events may be Cache Misses or Branch Mispredictions. These events can be observed and combined to create useful high-level metrics such as Cycles per Instruction (CPI).</p><a id="more"></a><p><img src="http://wx1.sinaimg.cn/mw690/672d88aagy1fd8s0n9jsqj219r0c4n00.jpg" alt="Pipeline"></p><p>The pipeline of a modern high-performance CPU is quite complex. In the simplified view blow, the pipeline is divided conceptually into two halves, the Front-end and the Back-end. The Front-end is responsible for fetching the program code represented in architectural instructions and decoding them into one or more low-level hardware operations called <em>micro-ops</em> (uOps). The uOps are then fed to the Back-end in a process called <em>allocation</em>. Once allocated, the Back-end is responsible for monitoring when uOp’s data operands are available and executing the uOp in an available execution unit. The completion of a uOp’s execution is called <em>retirement</em>, and is where results of the uOp are committed to the architectural state (CPU registers or written back to memory). Usually, most uOps pass completely through the pipeline and retire, but sometimes speculatively fetched uOps may get cancelled before retirement – like in the case of mispredicted branches.<br><img src="http://wx4.sinaimg.cn/large/672d88aagy1fd8sap5wrqg20xc0h2jsp.gif" alt="uOp Categories"></p><h1 id="Front-End-Bound"><a href="#Front-End-Bound" class="headerlink" title="Front-End Bound"></a>Front-End Bound</h1><p>Superscalar processors can be conceptually divided into the ‘front-end’, where instructions are fetched and decoded into the operations that constitute them; and the ‘back-end’, where the required computation is performed. Each cycle, the front-end generates up to four of these operations placed into pipeline slots that then move through the back-end. Thus, for a given execution duration in clock cycles, it is easy to determine the maximum number of pipeline slots containing useful work that can be retired in that duration. The actual number of retired pipeline slots containing useful work, though, rarely equals this maximum. This can be due to several factors: some pipeline slots cannot be filled with useful work, either because the front-end could not fetch or decode instructions in time (‘Front-end bound’ execution) or because the back-end was not prepared to accept more operations of a certain kind (‘Back-end bound’ execution). Moreover, even pipeline slots that do contain useful work may not retire due to bad speculation. Front-end bound execution may be due to a large code working set, poor code layout, or microcode assists. Back-end bound execution may be due to long-latency operations or other contention for execution resources. Bad speculation is most frequently due to branch misprediction.</p><p>A significant proportion of pipeline slots are remaining empty. Possible reasons include a large code working size, poor code layout (requiring too many memory accesses per cycle to get sufficient instructions to fill four pipeline slots), or microcode assists.</p><h2 id="gt-Front-End-Latency"><a href="#gt-Front-End-Latency" class="headerlink" title="&gt; Front-End Latency"></a>&gt; Front-End Latency</h2><p>This metric represents a fraction of slots during which CPU was stalled due to front-end latency issues, such as instruction-cache misses, ITLB misses or fetch stalls after a branch misprediction. In such cases, the front-end delivers no uOps.</p><h3 id="gt-gt-ICache-Misses"><a href="#gt-gt-ICache-Misses" class="headerlink" title="&gt;&gt; ICache Misses"></a>&gt;&gt; ICache Misses</h3><p>To introduce new uOps into the pipeline, the core must either fetch them from a decoded instruction cache, or fetch the instructions themselves from memory and then decode them. In the latter path, the requests to memory first go through the L1I (level 1 instruction) cache that caches the recent code working set. Front-end stalls can accrue when fetched instructions are not present in the L1I. Possible reasons are a large code working set or fragmentation between hot and cold code. In the latter case, when a hot instruction is fetched into the L1I, any cold code on its cache line is brought along with it. This may result in the eviction of other, hotter code.</p><h3 id="gt-gt-ITLB-Overhead"><a href="#gt-gt-ITLB-Overhead" class="headerlink" title="&gt;&gt; ITLB Overhead"></a>&gt;&gt; ITLB Overhead</h3><p>In x86 architectures, mappings between virtual and physical memory are facilitated by a page table, which is kept in memory. To minimize references to this table, recently-used portions of the page table are cached in a hierarchy of ‘translation look-aside buffers’, or TLBs, which are consulted on every virtual address translation. As with data caches, the farther a request has to go to be satisfied, the worse the performance impact. This metric estimates the performance penalty of page walks induced on ITLB (instruction TLB) misses.</p><h3 id="gt-gt-Branch-Resteers"><a href="#gt-gt-Branch-Resteers" class="headerlink" title="&gt;&gt; Branch Resteers"></a>&gt;&gt; Branch Resteers</h3><p>This metric represents cycles fraction the CPU was stalled due to Branch Resteers. Branch Resteers estimates the Frontend delay in fetching operations from corrected path, following all sorts of mispredicted branches. For example, branchy code with lots of misprediction might get categorized under Branch Resteers. Note the value of this node may overlap with its siblings.</p><h3 id="gt-gt-DSB-Switches"><a href="#gt-gt-DSB-Switches" class="headerlink" title="&gt;&gt; DSB Switches"></a>&gt;&gt; DSB Switches</h3><p>Intel microarchitecture code name Sandy Bridge introduces a new decoded ICache. This cache, called the DSB (Decoded Stream Buffer), stores uOps that have already been decoded, avoiding many of the penalties of the legacy decode pipeline, called the MITE (Micro-instruction Translation Engine). However, when control flows out of the region cached in the DSB, the front-end incurs a penalty as uOp issue switches from the DSB to the MITE. This metric measures this penalty.</p><h3 id="gt-gt-Length-Changing-Prefixes"><a href="#gt-gt-Length-Changing-Prefixes" class="headerlink" title="&gt;&gt; Length Changing Prefixes"></a>&gt;&gt; Length Changing Prefixes</h3><p>This metric represents a fraction of cycles during which CPU was stalled due to Length Changing Prefixes (LCPs). To avoid this issue, use proper compiler flags. Intel Compiler enables these flags by default.</p><h3 id="gt-gt-MS-Switches"><a href="#gt-gt-MS-Switches" class="headerlink" title="&gt;&gt; MS Switches"></a>&gt;&gt; MS Switches</h3><p>This metric represents a fraction of cycles when the CPU was stalled due to switches of uOp delivery to the Microcode Sequencer (MS). Commonly used instructions are optimized for delivery by the DSB or MITE pipelines. Certain operations cannot be handled natively by the execution pipeline, and must be performed by microcode (small programs injected into the execution stream). Switching to the MS too often can negatively impact performance. The MS is designated to deliver long uOp flows required by CISC instructions like CPUID, or uncommon conditions like Floating Point Assists when dealing with Denormals.</p><h2 id="gt-Front-End-Bandwidth"><a href="#gt-Front-End-Bandwidth" class="headerlink" title="&gt; Front-End Bandwidth"></a>&gt; Front-End Bandwidth</h2><p>This metric represents a fraction of slots during which CPU was stalled due to front-end bandwidth issues, such as inefficiencies in the instruction decoders or code restrictions for caching in the DSB (decoded uOps cache). In such cases, the front-end typically delivers a non-optimal amount of uOps to the back-end.</p><h3 id="gt-gt-Front-End-Bandwidth-MITE"><a href="#gt-gt-Front-End-Bandwidth-MITE" class="headerlink" title="&gt;&gt; Front-End Bandwidth MITE"></a>&gt;&gt; Front-End Bandwidth MITE</h3><p>This metric represents a fraction of cycles during which CPU was stalled due to the MITE fetch pipeline issues, such as inefficiencies in the instruction decoders.</p><h3 id="gt-gt-Front-End-Bandwidth-DSB"><a href="#gt-gt-Front-End-Bandwidth-DSB" class="headerlink" title="&gt;&gt; Front-End Bandwidth DSB"></a>&gt;&gt; Front-End Bandwidth DSB</h3><p>This metric represents a fraction of cycles during which CPU was likely limited due to DSB (decoded uOp cache) fetch pipeline. For example, inefficient utilization of the DSB cache structure or bank conflict when reading from it, are categorized here.</p><h3 id="gt-gt-Front-End-Bandwidth-LSD"><a href="#gt-gt-Front-End-Bandwidth-LSD" class="headerlink" title="&gt;&gt; Front-End Bandwidth LSD"></a>&gt;&gt; Front-End Bandwidth LSD</h3><p>This metric represents a fraction of cycles during which CPU operation was limited by the LSD (Loop Stream Detector) unit. Typically, LSD provides good uOp supply. However, in some rare cases, optimal uOp delivery cannot be reached for small loops whose size (in terms of number of uOps) does not suit well the LSD structure.</p><h1 id="Bad-Speculation"><a href="#Bad-Speculation" class="headerlink" title="Bad Speculation"></a>Bad Speculation</h1><h2 id="gt-Branch-Mispredict"><a href="#gt-Branch-Mispredict" class="headerlink" title="&gt; Branch Mispredict"></a>&gt; Branch Mispredict</h2><p>When a branch mispredicts, some instructions from the mispredicted path still move through the pipeline. All work performed on these instructions is wasted since they would not have been executed had the branch been correctly predicted. This metric represents slots fraction the CPU has wasted due to Branch Misprediction. These slots are either wasted by uOps fetched from an incorrectly speculated program path, or stalls when the out-of-order part of the machine needs to recover its state from a speculative path.</p><h2 id="gt-Machine-Clears"><a href="#gt-Machine-Clears" class="headerlink" title="&gt; Machine Clears"></a>&gt; Machine Clears</h2><p>Certain events require the entire pipeline to be cleared and restarted from just after the last retired instruction. This metric measures three such events: memory ordering violations, self-modifying code, and certain loads to illegal address ranges. Machine Clears metric represents slots fraction the CPU has wasted due to Machine Clears. These slots are either wasted by uOps fetched prior to the clear, or stalls the out-of-order portion of the machine needs to recover its state after the clear.</p><h1 id="Back-End-Bound"><a href="#Back-End-Bound" class="headerlink" title="Back-End Bound"></a>Back-End Bound</h1><p>Identify slots where no uOps are delivered due to a lack of required resources for accepting more uOps in the back-end of the pipeline. Back-end metrics describe a portion of the pipeline where the out-of-order scheduler dispatches ready uOps into their respective execution units, and, once completed, these uOps get retired according to program order. Stalls due to data-cache misses or stalls due to the overloaded divider unit are examples of back-end bound issues.</p><h2 id="gt-Memory-Bound"><a href="#gt-Memory-Bound" class="headerlink" title="&gt; Memory Bound"></a>&gt; Memory Bound</h2><p>This metric shows how memory subsystem issues affect the performance. Memory Bound measures a fraction of slots where pipeline could be stalled due to demand load or store instructions. This accounts mainly for incomplete in-flight memory demand loads that coincide with execution starvation in addition to less common cases where stores could imply back-pressure on the pipeline.</p><h3 id="gt-gt-L1-Bound"><a href="#gt-gt-L1-Bound" class="headerlink" title="&gt;&gt; L1 Bound"></a>&gt;&gt; L1 Bound</h3><p>This metric shows how often machine was stalled without missing the L1 data cache. The L1 cache typically has the shortest latency. However, in certain cases like loads blocked on older stores, a load might suffer a high latency even though it is being satisfied by the L1.</p><h4 id="gt-gt-gt-DTLB-Overhead"><a href="#gt-gt-gt-DTLB-Overhead" class="headerlink" title="&gt;&gt;&gt; DTLB Overhead"></a>&gt;&gt;&gt; DTLB Overhead</h4><p>This metric estimates the performance penalty paid for missing the first-level data TLB (DTLB) that includes hitting in the second-level data TLB (STLB) as well as performing a hardware page walk on an STLB miss.</p><h4 id="gt-gt-gt-Loads-Blocked-by-Store-Forwarding"><a href="#gt-gt-gt-Loads-Blocked-by-Store-Forwarding" class="headerlink" title="&gt;&gt;&gt; Loads Blocked by Store Forwarding"></a>&gt;&gt;&gt; Loads Blocked by Store Forwarding</h4><p>To streamline memory operations in the pipeline, a load can avoid waiting for memory if a prior store, still in flight, is writing the data that the load wants to read (a ‘store forwarding’ process). However, in some cases, generally when the prior store is writing a smaller region than the load is reading, the load is blocked for a significant time pending the store forward. This metric measures the performance penalty of such blocked loads.</p><h4 id="gt-gt-gt-Lock-Latency"><a href="#gt-gt-gt-Lock-Latency" class="headerlink" title="&gt;&gt;&gt; Lock Latency"></a>&gt;&gt;&gt; Lock Latency</h4><p>This metric represents cycles fraction the CPU spent handling cache misses due to lock operations. Due to the microarchitecture handling of locks, they are classified as L1 Bound regardless of what memory source satisfied them.</p><h4 id="gt-gt-gt-Split-Loads"><a href="#gt-gt-gt-Split-Loads" class="headerlink" title="&gt;&gt;&gt; Split Loads"></a>&gt;&gt;&gt; Split Loads</h4><p>Throughout the memory hierarchy, data moves at cache line granularity - 64 bytes per line. Although this is much larger than many common data types, such as integer, float, or double, unaligned values of these or other types may span two cache lines. Recent Intel architectures have significantly improved the performance of such ‘split loads’ by introducing split registers to handle these cases, but split loads can still be problematic, especially if many split loads in a row consume all available split registers.</p><h4 id="gt-gt-gt-4K-Aliasing"><a href="#gt-gt-gt-4K-Aliasing" class="headerlink" title="&gt;&gt;&gt; 4K Aliasing"></a>&gt;&gt;&gt; 4K Aliasing</h4><p>When an earlier (in program order) load issued after a later (in program order) store, a potential WAR (write-after-read) hazard exists. To detect such hazards, the memory order buffer (MOB) compares the low-order 12 bits of the load and store in every potential WAR hazard. If they match, the load is reissued, penalizing performance. However, as only 12 bits are compared, a WAR hazard may be detected falsely on loads and stores whose addresses are separated by a multiple of 4096 (2^12). This metric estimates the performance penalty of handling such falsely aliasing loads and stores.</p><h4 id="gt-gt-gt-FB-Full"><a href="#gt-gt-gt-FB-Full" class="headerlink" title="&gt;&gt;&gt; FB Full"></a>&gt;&gt;&gt; FB Full</h4><p>This metric does a rough estimation of how often L1D Fill Buffer unavailability limited additional L1D miss memory access requests to proceed. The higher the metric value, the deeper the memory hierarchy level the misses are satisfied from. Often it hints on approaching bandwidth limits (to L2 cache, L3 cache or external memory).</p><h3 id="gt-gt-L2-Bound"><a href="#gt-gt-L2-Bound" class="headerlink" title="&gt;&gt; L2 Bound"></a>&gt;&gt; L2 Bound</h3><p>This metric shows how often machine was stalled on L2 cache. Avoiding cache misses (L1 misses/L2 hits) will improve the latency and increase performance.</p><h3 id="gt-gt-L3-Bound"><a href="#gt-gt-L3-Bound" class="headerlink" title="&gt;&gt; L3 Bound"></a>&gt;&gt; L3 Bound</h3><p>This metric shows how often CPU was stalled on L3 cache, or contended with a sibling Core. Avoiding cache misses (L2 misses/L3 hits) improves the latency and increases performance.</p><h4 id="gt-gt-gt-Contested-Accesses"><a href="#gt-gt-gt-Contested-Accesses" class="headerlink" title="&gt;&gt;&gt; Contested Accesses"></a>&gt;&gt;&gt; Contested Accesses</h4><p>Contested accesses occur when data written by one thread is read by another thread on a different core. Examples of contested accesses include synchronizations such as locks, true data sharing such as modified locked variables, and false sharing. This metric is a ratio of cycles generated while the caching system was handling contested accesses to all cycles.</p><h4 id="gt-gt-gt-Data-Sharing"><a href="#gt-gt-gt-Data-Sharing" class="headerlink" title="&gt;&gt;&gt; Data Sharing"></a>&gt;&gt;&gt; Data Sharing</h4><p>Data shared by multiple threads (even just read shared) may cause increased access latency due to cache coherency. This metric measures the impact of that coherency. Excessive data sharing can drastically harm multithreaded performance. This metric is defined by the ratio of cycles while the caching system is handling shared data to all cycles. It does not measure waits due to contention on a variable, which is measured by the Locks and Waits analysis.</p><h4 id="gt-gt-gt-L3-Latency"><a href="#gt-gt-gt-L3-Latency" class="headerlink" title="&gt;&gt;&gt; L3 Latency"></a>&gt;&gt;&gt; L3 Latency</h4><p>This metric shows a fraction of cycles with demand load accesses that hit the L3 cache under unloaded scenarios (possibly L3 latency limited). Avoiding private cache misses (i.e. L2 misses/L3 hits) will improve the latency, reduce contention with sibling physical cores and increase performance. Note the value of this node may overlap with its siblings.</p><h4 id="gt-gt-gt-SQ-Full"><a href="#gt-gt-gt-SQ-Full" class="headerlink" title="&gt;&gt;&gt; SQ Full"></a>&gt;&gt;&gt; SQ Full</h4><p>This metric measures fraction of cycles where the Super Queue (SQ) was full taking into account all request-types and both hardware SMT threads. The Super Queue is used for requests to access the L2 cache or to go out to the Uncore.</p><h3 id="gt-gt-DRAM-Bound"><a href="#gt-gt-DRAM-Bound" class="headerlink" title="&gt;&gt; DRAM Bound"></a>&gt;&gt; DRAM Bound</h3><p>This metric shows how often CPU was stalled on the main memory (DRAM). Caching typically improves the latency and increases performance.</p><h4 id="gt-gt-gt-Memory-Bandwidth"><a href="#gt-gt-gt-Memory-Bandwidth" class="headerlink" title="&gt;&gt;&gt; Memory Bandwidth"></a>&gt;&gt;&gt; Memory Bandwidth</h4><p>This metric represents a fraction of cycles during which an application could be stalled due to approaching bandwidth limits of the main memory (DRAM). This metric does not aggregate requests from other threads/cores/sockets (see Uncore counters for that). Consider improving data locality in NUMA multi-socket systems.</p><h4 id="gt-gt-gt-Memory-Latency"><a href="#gt-gt-gt-Memory-Latency" class="headerlink" title="&gt;&gt;&gt; Memory Latency"></a>&gt;&gt;&gt; Memory Latency</h4><p>This metric represents a fraction of cycles during which an application could be stalled due to the latency of the main memory (DRAM). This metric does not aggregate requests from other threads/cores/sockets (see Uncore counters for that). Consider optimizing data layout or using Software Prefetches (through the compiler).</p><p><strong>LLC Miss: </strong>The LLC (last-level cache) is the last, and longest-latency, level in the memory hierarchy before main memory (DRAM). Any memory requests missing here must be serviced by local or remote DRAM, with significant latency. The LLC Miss metric shows a ratio of cycles with outstanding LLC misses to all cycles.</p><h3 id="gt-gt-Store-Bound"><a href="#gt-gt-Store-Bound" class="headerlink" title="&gt;&gt; Store Bound"></a>&gt;&gt; Store Bound</h3><p>This metric shows how often CPU was stalled on store operations. Even though memory store accesses do not typically stall out-of-order CPUs; there are few cases where stores can lead to actual stalls. Consider False Sharing analysis as your next step.</p><h4 id="gt-gt-gt-Store-Latency"><a href="#gt-gt-gt-Store-Latency" class="headerlink" title="&gt;&gt;&gt; Store Latency"></a>&gt;&gt;&gt; Store Latency</h4><p>This metric represents cycles fraction the CPU spent handling long-latency store misses (missing 2nd level cache). Consider avoiding/reducing unnecessary (or easily loadable/computable) memory store. Note that this metric value may be highlighted due to a Lock Latency issue.</p><h4 id="gt-gt-gt-False-Sharing"><a href="#gt-gt-gt-False-Sharing" class="headerlink" title="&gt;&gt;&gt; False Sharing"></a>&gt;&gt;&gt; False Sharing</h4><p>This metric shows how often CPU was stalled on store operations to a shared cache line. It can be easily avoided by padding to make threads access different lines.</p><h4 id="gt-gt-gt-Split-Stores"><a href="#gt-gt-gt-Split-Stores" class="headerlink" title="&gt;&gt;&gt; Split Stores"></a>&gt;&gt;&gt; Split Stores</h4><p>This metric represents a rate of split store accesses. Consider aligning your data to the 64-byte cache line granularity.</p><h4 id="gt-gt-gt-DTLB-Store-Overhead"><a href="#gt-gt-gt-DTLB-Store-Overhead" class="headerlink" title="&gt;&gt;&gt; DTLB Store Overhead"></a>&gt;&gt;&gt; DTLB Store Overhead</h4><p>This metric represents a fraction of cycles spent on handling first-level data TLB store misses. As with ordinary data caching, focus on improving data locality and reducing working-set size to reduce DTLB overhead. Additionally, consider using profile-guided optimization (PGO) to collocate frequently-used data on the same page. Try using larger page sizes for large amounts of frequently-used data.</p><h2 id="gt-Core-Bound"><a href="#gt-Core-Bound" class="headerlink" title="&gt; Core Bound"></a>&gt; Core Bound</h2><p>This metric represents how much Core non-memory issues were of a bottleneck. Shortage in hardware compute resources, or dependencies software’s instructions are both categorized under Core Bound. Hence it may indicate the machine ran out of an OOO resources, certain execution units are overloaded or dependencies in program’s data- or instruction- flow are limiting the performance (e.g. FP-chained long-latency arithmetic operations).</p><h3 id="gt-gt-Divider"><a href="#gt-gt-Divider" class="headerlink" title="&gt;&gt; Divider"></a>&gt;&gt; Divider</h3><p>Not all arithmetic operations take the same amount of time. Divides and square roots, both performed by the DIV unit, take considerably longer than integer or floating point addition, subtraction, or multiplication. This metric represents cycles fraction where the Divider unit was active.</p><h3 id="gt-gt-Port-Utilization"><a href="#gt-gt-Port-Utilization" class="headerlink" title="&gt;&gt; Port Utilization"></a>&gt;&gt; Port Utilization</h3><p>This metric represents a fraction of cycles during which an application was stalled due to Core non-divider-related issues. For example, heavy data-dependency between nearby instructions, or a sequence of instructions that overloads specific ports. Hint: Loop Vectorization - most compilers feature auto-Vectorization options today - reduces pressure on the execution ports as multiple elements are calculated with same uOp.</p><h1 id="Retiring"><a href="#Retiring" class="headerlink" title="Retiring"></a>Retiring</h1></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">------本文结束&nbsp<i class="fa fa-paw"></i>&nbsp感谢阅读------</div></div></div><div></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>君慷以解囊 吾抱以琼瑶</div><button id="rewardButton" disable="enable" onclick='var e=document.getElementById("QR");"none"===e.style.display?e.style.display="block":e.style.display="none"'><span style="font-size:25px">赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/pay-wechat.jpg" alt="Hamster Si WeChat Pay"><p>微信打赏</p></div><div id="alipay" style="display:inline-block"><img id="alipay_qr" src="/images/pay-alipay.jpg" alt="Hamster Si Alipay"><p>支付宝打赏</p></div></div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/02/Economics-in-One-Lesson/" rel="next" title="Economics in One Lesson"><i class="fa fa-chevron-left"></i> Economics in One Lesson</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/03/2014-09-New-Brighton-@-Christchurch/" rel="prev" title="2014 - 09 New Brighton @ Christchurch.md">2014 - 09 New Brighton @ Christchurch.md <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"></div></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview">站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/logo@2x.png" alt="Hamster Si"><p class="site-author-name" itemprop="name">Hamster Si</p><p class="site-description motion-element" itemprop="description">生性涼薄 擇木而修</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">12</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories"><span class="site-state-item-count">3</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="http://hamstersi.com/about/" target="_blank" title="WeChat" class="social-link-format"><i class="fa fa-fw fa-wechat"></i> WeChat </a></span><span class="links-of-author-item"><a href="http://www.weibo.com/suluoai/" target="_blank" title="Weibo" class="social-link-format"><i class="fa fa-fw fa-weibo"></i> Weibo </a></span><span class="links-of-author-item"><a href="https://github.com/HamsterSi/" target="_blank" title="GitHub" class="social-link-format"><i class="fa fa-fw fa-github"></i> GitHub</a></span></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Front-End-Bound"><span class="nav-number">1.</span> <span class="nav-text">Front-End Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Front-End-Latency"><span class="nav-number">1.1.</span> <span class="nav-text">> Front-End Latency</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-ICache-Misses"><span class="nav-number">1.1.1.</span> <span class="nav-text">>> ICache Misses</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-ITLB-Overhead"><span class="nav-number">1.1.2.</span> <span class="nav-text">>> ITLB Overhead</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Branch-Resteers"><span class="nav-number">1.1.3.</span> <span class="nav-text">>> Branch Resteers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-DSB-Switches"><span class="nav-number">1.1.4.</span> <span class="nav-text">>> DSB Switches</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Length-Changing-Prefixes"><span class="nav-number">1.1.5.</span> <span class="nav-text">>> Length Changing Prefixes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-MS-Switches"><span class="nav-number">1.1.6.</span> <span class="nav-text">>> MS Switches</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Front-End-Bandwidth"><span class="nav-number">1.2.</span> <span class="nav-text">> Front-End Bandwidth</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Front-End-Bandwidth-MITE"><span class="nav-number">1.2.1.</span> <span class="nav-text">>> Front-End Bandwidth MITE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Front-End-Bandwidth-DSB"><span class="nav-number">1.2.2.</span> <span class="nav-text">>> Front-End Bandwidth DSB</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Front-End-Bandwidth-LSD"><span class="nav-number">1.2.3.</span> <span class="nav-text">>> Front-End Bandwidth LSD</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Bad-Speculation"><span class="nav-number">2.</span> <span class="nav-text">Bad Speculation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Branch-Mispredict"><span class="nav-number">2.1.</span> <span class="nav-text">> Branch Mispredict</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Machine-Clears"><span class="nav-number">2.2.</span> <span class="nav-text">> Machine Clears</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Back-End-Bound"><span class="nav-number">3.</span> <span class="nav-text">Back-End Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Memory-Bound"><span class="nav-number">3.1.</span> <span class="nav-text">> Memory Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-L1-Bound"><span class="nav-number">3.1.1.</span> <span class="nav-text">>> L1 Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-DTLB-Overhead"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">>>> DTLB Overhead</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Loads-Blocked-by-Store-Forwarding"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">>>> Loads Blocked by Store Forwarding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Lock-Latency"><span class="nav-number">3.1.1.3.</span> <span class="nav-text">>>> Lock Latency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Split-Loads"><span class="nav-number">3.1.1.4.</span> <span class="nav-text">>>> Split Loads</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-4K-Aliasing"><span class="nav-number">3.1.1.5.</span> <span class="nav-text">>>> 4K Aliasing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-FB-Full"><span class="nav-number">3.1.1.6.</span> <span class="nav-text">>>> FB Full</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-L2-Bound"><span class="nav-number">3.1.2.</span> <span class="nav-text">>> L2 Bound</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-L3-Bound"><span class="nav-number">3.1.3.</span> <span class="nav-text">>> L3 Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Contested-Accesses"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">>>> Contested Accesses</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Data-Sharing"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">>>> Data Sharing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-L3-Latency"><span class="nav-number">3.1.3.3.</span> <span class="nav-text">>>> L3 Latency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-SQ-Full"><span class="nav-number">3.1.3.4.</span> <span class="nav-text">>>> SQ Full</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-DRAM-Bound"><span class="nav-number">3.1.4.</span> <span class="nav-text">>> DRAM Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Memory-Bandwidth"><span class="nav-number">3.1.4.1.</span> <span class="nav-text">>>> Memory Bandwidth</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Memory-Latency"><span class="nav-number">3.1.4.2.</span> <span class="nav-text">>>> Memory Latency</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Store-Bound"><span class="nav-number">3.1.5.</span> <span class="nav-text">>> Store Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Store-Latency"><span class="nav-number">3.1.5.1.</span> <span class="nav-text">>>> Store Latency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-False-Sharing"><span class="nav-number">3.1.5.2.</span> <span class="nav-text">>>> False Sharing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-Split-Stores"><span class="nav-number">3.1.5.3.</span> <span class="nav-text">>>> Split Stores</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gt-gt-gt-DTLB-Store-Overhead"><span class="nav-number">3.1.5.4.</span> <span class="nav-text">>>> DTLB Store Overhead</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gt-Core-Bound"><span class="nav-number">3.2.</span> <span class="nav-text">> Core Bound</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Divider"><span class="nav-number">3.2.1.</span> <span class="nav-text">>> Divider</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gt-gt-Port-Utilization"><span class="nav-number">3.2.2.</span> <span class="nav-text">>> Port Utilization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Retiring"><span class="nav-number">4.</span> <span class="nav-text">Retiring</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2017</span> - <span class="author" itemprop="copyrightHolder">Hamster Si</span></div><div class="powered-by">HamsterSi.com</div><div class="theme-info">Powered By <a class="theme-link" href="https://www.qcloud.com/">QCloud</a>, <a class="theme-link" href="https://hexo.io">HEXO</a>, <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script></body></html>